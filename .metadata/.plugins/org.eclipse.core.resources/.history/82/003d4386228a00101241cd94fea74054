package crawlerDesign2;

import java.util.ArrayList;
import java.util.List;

import org.jsoup.Connection;
import org.jsoup.Connection.Response;
import org.jsoup.Jsoup;

import crawlerDesign.ProductData;

public class DmartScraper {
	private static final String BASE_URL = "https://digital.dmart.in/api/v3/plp/biscuits---cookies-aesc-biscuitsandcookies";
	private static final int PAGE_SIZE = 40;
	private static final String STORE_ID = "10151";
	
	public List<ProductData> scrapeAllProds(){
		List<ProductData> allProducts = new ArrayList();
		
		int currPage =1;
		boolean hasNextPage=true;
		
		while(hasNextPage) {
			System.out.println("Scraping page " + currPage);
			
			try {
			String jsonResp = fetchPageData(currPage);
			List<ProductData> prodsOnCurrPage = parseProductsFromJson(jsonResp);
			}catch (Exception e){
				System.out.println("Error" + e);
				
			}
			
			
		}
		
	}
	
	private String fetchPageData(int pageNo) throws Exception {
		String url = BASE_URL + "?page="+pageNo+"&size="+PAGE_SIZE+"&channel=web&storeId=" + STORE_ID;
		
		Response res = Jsoup.connect(url)
				.userAgent("Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:142.0) Gecko/20100101 Firefox/142.0")
				.header("Acept", "application/json, text/plain, */*")
				.header("Accept-Language", "en-US,en;q=0.5")
				.ignoreContentType(true)
				.method(Connection.Method.GET).execute();
		
		return res.body();
	}
	
	private List<ProductData> parseProductsFromJson(String res){
		List<ProductData> products = new ArrayList();
		
		
	}
	

	
	
	
	
	
	
	
	
	
	
	
}
