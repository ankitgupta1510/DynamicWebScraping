import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

import org.json.JSONArray;
import org.json.JSONObject;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class WebScraper {

    // Yeh ek nested class hai configuration store karne ke liye.
    // Isse hum scraper ko batate hain ki KYA aur KAHAN se scrape karna hai.
    static class ScraperConfig {
        private String url;
        private String itemContainerSelector; // Har item ko select karne wala CSS selector
        private Map<String, String> dataPoints; // Data ka naam aur uska CSS selector

        public ScraperConfig(String url, String itemContainerSelector) {
            this.url = url;
            this.itemContainerSelector = itemContainerSelector;
            this.dataPoints = new HashMap<>();
        }

        public void addDataPoint(String name, String selector) {
            this.dataPoints.put(name, selector);
        }

        public String getUrl() {
            return url;
        }

        public String getItemContainerSelector() {
            return itemContainerSelector;
        }

        public Map<String, String> getDataPoints() {
            return dataPoints;
        }
    }

    /**
     * Yeh main scraping logic wala function hai.
     * @param config ScraperConfig object jismein saari details hain.
     * @return Scrape kiya hua data JSON format mein as a String.
     */
    public String scrape(ScraperConfig config) {
        JSONArray resultsArray = new JSONArray();

        try {
            // 1. Website se connect karke HTML document fetch karna
            System.out.println("Connecting to " + config.getUrl() + "...");
            Document doc = Jsoup.connect(config.getUrl()).userAgent("Mozilla/5.0").get();
            System.out.println("Connection successful!");

            // 2. Saare items (jaise products, articles) ko select karna
            Elements items = doc.select(config.getItemContainerSelector());
            System.out.println("Found " + items.size() + " items to scrape.");

            // 3. Har item par loop karke data extract karna
            for (Element item : items) {
                JSONObject itemJson = new JSONObject();

                // Har data point ke liye (jo config mein define kiya hai)
                for (Map.Entry<String, String> entry : config.getDataPoints().entrySet()) {
                    String dataName = entry.getKey();
                    String selector = entry.getValue();
                    
                    Element dataElement = item.selectFirst(selector);
                    String extractedText = (dataElement != null) ? dataElement.text() : "Not Found";
                    
                    // Agar title jaise cheez attribute mein hai to use kaise nikalein
                    // Example: <a href="..." title="The Book Title">...</a>
                    if (selector.contains("[") && selector.contains("]")) {
                         String attribute = selector.substring(selector.indexOf("[") + 1, selector.indexOf("]"));
                         if (dataElement != null) {
                            extractedText = dataElement.attr(attribute);
                         }
                    }

                    itemJson.put(dataName, extractedText);
                }
                resultsArray.put(itemJson);
            }

        } catch (IOException e) {
            System.err.println("Scraping failed for URL: " + config.getUrl());
            e.printStackTrace();
            return new JSONObject().put("error", "Could not fetch the page. Check URL and connection.").toString();
        }

        // 4. Final JSON string return karna (sundar format mein)
        return resultsArray.toString(4);
    }

    public static void main(String[] args) {
        WebScraper scraper = new WebScraper();

        // --- EXAMPLE: books.toscrape.com ko scrape karna ---
        // Step 1: Configuration object banana
        ScraperConfig bookScraperConfig = new ScraperConfig(
            "http://books.toscrape.com/",  // Website ka URL
            "article.product_pod"          // Har book ke container ka CSS selector
        );

        // Step 2: Batana ki kya-kya data nikalna hai
        // Data ka Naam, Uska CSS Selector
        bookScraperConfig.addDataPoint("Book Title", "h3 > a[title]");
        bookScraperConfig.addDataPoint("Price", "p.price_color");
        bookScraperConfig.addDataPoint("Stock Availability", "p.instock.availability");

        // Step 3: Scraper ko run karna
        System.out.println("--- Starting Scraper for Books.toscrape.com ---");
        String scrapedData = scraper.scrape(bookScraperConfig);

        // Step 4: Result ko print karna
        System.out.println("\n--- SCRAPED DATA ---");
        System.out.println(scrapedData);
        System.out.println("--------------------\n");
        
        // --- Nayi website ke liye bas yahan se config badal dein ---
        // EXAMPLE 2: quotes.toscrape.com ko scrape karna
        ScraperConfig quoteScraperConfig = new ScraperConfig(
            "http://quotes.toscrape.com/",
            "div.quote"
        );
        quoteScraperConfig.addDataPoint("Quote", "span.text");
        quoteScraperConfig.addDataPoint("Author", "small.author");
        
        System.out.println("--- Starting Scraper for Quotes.toscrape.com ---");
        String scrapedQuotes = scraper.scrape(quoteScraperConfig);
        System.out.println("\n--- SCRAPED QUOTES ---");
        System.out.println(scrapedQuotes);
        System.out.println("--------------------");
    }
}
